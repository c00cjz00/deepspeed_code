{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nGPU Training\n",
    "- 重切換到 Python 3 (ipykernel)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "!git clone https://github.com/hiyouga/LLaMA-Factory.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEEPSPEED CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## 請記得修HF_TOKEN='hf_' , 給予huggingface token\n",
    "## 將模型微調指令寫成 demo.cmd\n",
    "## 特別注意虛擬絕對路徑部分 /DEEPSPEED/LLaMA-Factory (為你目前執行目錄下必須有LLaMA-Factory目錄)\n",
    "## --model_name_or_path meta-llama/Llama-2-7b-hf\n",
    "## --model_name_or_path /work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf\n",
    "##     --deepspeed examples/full_multi_gpu/ds_z3_config.json \\\n",
    "\n",
    "cat << \\EOF >  demo.cmd\n",
    "#!/bin/bash\n",
    "\n",
    "# 虛擬絕對路徑\n",
    "cd /DEEPSPEED/LLaMA-Factory\n",
    "\n",
    "## 清空之前計算\n",
    "ps -ef |grep 'train_bash.py' | awk '{print $2}' | xargs kill -9\n",
    "rm -rf ../saves/LLaMA2-7B/lora/sft\n",
    "sleep 10\n",
    "\n",
    "## 微調程式\n",
    "deepspeed --num_gpus ${GPUS_PER_NODE} src/train_bash.py \\\n",
    "    --deepspeed examples/full_multi_gpu/ds_z2_config.json \\\n",
    "    --stage sft \\\n",
    "    --do_train \\\n",
    "    --model_name_or_path /work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf \\\n",
    "    --dataset alpaca_gpt4_zh \\\n",
    "    --dataset_dir data \\\n",
    "    --template default \\\n",
    "    --finetuning_type lora \\\n",
    "    --lora_target q_proj,v_proj \\\n",
    "    --output_dir ../saves/LLaMA2-7B/lora/sft \\\n",
    "    --overwrite_cache \\\n",
    "    --overwrite_output_dir \\\n",
    "    --cutoff_len 1024 \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --evaluation_strategy steps \\\n",
    "    --load_best_model_at_end \\\n",
    "    --learning_rate 5e-5 \\\n",
    "    --num_train_epochs 3.0 \\\n",
    "    --max_samples 1000 \\\n",
    "    --val_size 0.1 \\\n",
    "    --plot_loss \\\n",
    "    --fp16\n",
    "\n",
    "EOF\n",
    "\n",
    "## 改變執行檔權限並印出\n",
    "chmod 755 demo.cmd\n",
    "#cat demo.cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLURM JOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# SLURM 工作配送 \n",
    "# --nodes=2 (2台電腦) \n",
    "# --gres=gpu:2 (每台電腦2顆GPU)\n",
    "# -c 8  (每台電腦　8 CORE CPU)\n",
    "\n",
    "## 將 << \\EOF > .... EOF  之間文字 儲存成 demo.slurm\n",
    "cat << \\EOF >  demo.slurm\n",
    "#!/bin/bash\n",
    "#SBATCH -A MST110386                                                    ### project number, Example MST109178\n",
    "#SBATCH -J _t2demo_                                                     ### Job name, Exmaple jupyterlab\n",
    "#SBATCH -p gp4d                                                         ### Partition Name, Example ngs1gpu\n",
    "#SBATCH --nodes=1                                                       ### Nodes, Default 1, node number\n",
    "#SBATCH --ntasks-per-node=1                                             ### Tasks, Default 1, per node tasks\n",
    "#SBATCH -c 32                                                            ### Cores assigned to each task, Example 4\n",
    "#SBATCH --gres=gpu:8                                                    ### GPU number, Example gpu:1\n",
    "#SBATCH --time=0-1:00:00                                                ### Runnung time, days-hours:minutes:seconds or hours:minutes:seconds\n",
    "#SBATCH -o demo.out                                                     ### Log folder, Here %j is job ID\n",
    "#SBATCH -e demo.err \n",
    "\n",
    "## 環境變數\n",
    "export GPUS_PER_NODE=8\n",
    "\n",
    "## 用Singularity 容器執行上方demo.cmd\n",
    "## $PWD:/DEEPSPEED 交目前目錄掛載成虛擬目錄 /DEEPSPEED, 對應上個CELL  虛擬絕對路徑 cd /DEEPSPEED/LLaMA-Factory\n",
    "srun singularity exec --nv \\\n",
    "-B $PWD:/DEEPSPEED \\\n",
    "-B /work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf \\\n",
    "/work/u00cjz00/nvidia/cuda118/c00cjz00_cuda11.8_pytorch_2.1.2-cuda11.8-cudnn8-devel-llama_factory.sif \\\n",
    "bash -c '/DEEPSPEED/demo.cmd'\n",
    "EOF\n",
    "\n",
    "## 改變執行檔權限並印出\n",
    "chmod 755 demo.slurm\n",
    "#cat demo.slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 開始配送工作 (請將下面 # 取消, 進行工作派送)\n",
    "!sbatch  demo.slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 觀看派送結果\n",
    "!echo \"觀看派送結果\"\n",
    "!squeue -u $(whoami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 印出派送運算訊息\n",
    "!echo \"印出派送運算訊息\"\n",
    "!tail -f demo.out demo.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 刪除工作 scancel $JOBID\n",
    "!scancel 578428   578429                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
